#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SSEæ•°æ®æµæ·±åº¦åˆ†æå·¥å…·
å¯¹æ¯”ç›´æ¥Anthropic APIä¸æœ¬é¡¹ç›®çš„å“åº”å·®å¼‚
"""

import time
import json
import requests
import threading
from datetime import datetime
from collections import defaultdict
import sys

class SSEAnalyzer:
    """SSEæ•°æ®æµåˆ†æå™¨"""

    def __init__(self):
        self.chunks = []
        self.timings = []
        self.start_time = None

    def analyze_sse_stream(self, response, source_name):
        """åˆ†æSSEæ•°æ®æµ"""
        self.chunks = []
        self.timings = []
        self.start_time = time.time()

        print(f"\nğŸ” åˆ†æ {source_name} çš„SSEæ•°æ®æµ...")

        for line in response.iter_lines(decode_unicode=True):
            if line and line.startswith('data:'):
                current_time = time.time()
                elapsed = (current_time - self.start_time) * 1000

                chunk_data = {
                    'timestamp': current_time,
                    'elapsed_ms': elapsed,
                    'raw_line': line,
                    'content': line[5:].strip(),  # ç§»é™¤ "data: " å‰ç¼€
                    'size': len(line.encode('utf-8'))
                }

                self.chunks.append(chunk_data)
                self.timings.append(elapsed)

                # æ‰“å°å‰å‡ ä¸ªæ•°æ®å—
                if len(self.chunks) <= 5:
                    print(f"  å— {len(self.chunks)}: {elapsed:.2f}ms - {line[:80]}...")

                if '[DONE]' in line:
                    break

        return self.get_analysis(source_name)

    def get_analysis(self, source_name):
        """è·å–åˆ†æç»“æœ"""
        if not self.chunks:
            return {"error": "æ— æ•°æ®"}

        # è®¡ç®—æ—¶é—´é—´éš”
        intervals = []
        for i in range(1, len(self.chunks)):
            interval = self.chunks[i]['elapsed_ms'] - self.chunks[i-1]['elapsed_ms']
            intervals.append(interval)

        # åˆ†ææ•°æ®å—ç±»å‹
        block_types = defaultdict(int)
        for chunk in self.chunks:
            try:
                if chunk['content'] == '[DONE]':
                    block_types['DONE'] += 1
                else:
                    data = json.loads(chunk['content'])
                    if isinstance(data, dict):
                        msg_type = data.get('type', 'unknown')
                        block_types[msg_type] += 1
            except:
                block_types['parse_error'] += 1

        analysis = {
            'source': source_name,
            'total_chunks': len(self.chunks),
            'total_time_ms': self.chunks[-1]['elapsed_ms'] if self.chunks else 0,
            'avg_chunk_size': sum(c['size'] for c in self.chunks) / len(self.chunks),
            'block_types': dict(block_types)
        }

        if intervals:
            analysis.update({
                'avg_interval_ms': sum(intervals) / len(intervals),
                'max_interval_ms': max(intervals),
                'min_interval_ms': min(intervals),
                'interval_std': self._std(intervals),
                'large_intervals': [i for i in intervals if i > 100],  # è¶…è¿‡100msçš„é—´éš”
                'small_intervals': [i for i in intervals if i < 10],   # å°äº10msçš„é—´éš”
            })

        return analysis

    def _std(self, values):
        """è®¡ç®—æ ‡å‡†å·®"""
        if not values:
            return 0
        mean = sum(values) / len(values)
        variance = sum((x - mean) ** 2 for x in values) / len(values)
        return variance ** 0.5

def test_direct_anthropic_api():
    """æµ‹è¯•ç›´æ¥Anthropic API"""
    print("\nğŸš€ æµ‹è¯•ç›´æ¥Anthropic API...")

    # è¿™é‡Œéœ€è¦çœŸå®çš„APIå¯†é’¥
    headers = {
        'Content-Type': 'application/json',
        'x-api-key': 'sk-ant-api03-...',  # éœ€è¦çœŸå®çš„å¯†é’¥
        'anthropic-version': '2023-06-01'
    }

    data = {
        "model": "claude-3-5-haiku-20241022",
        "max_tokens": 500,
        "messages": [
            {"role": "user", "content": "è¯·ç®€è¦å›ç­”1+1ç­‰äºå¤šå°‘ï¼Ÿ"}
        ],
        "stream": True
    }

    try:
        response = requests.post(
            "https://api.anthropic.com/v1/messages",
            headers=headers,
            json=data,
            stream=True,
            timeout=30
        )

        if response.status_code == 200:
            analyzer = SSEAnalyzer()
            return analyzer.analyze_sse_stream(response, "Direct Anthropic API")
        else:
            print(f"âŒ ç›´æ¥APIè¯·æ±‚å¤±è´¥: {response.status_code}")
            return None

    except Exception as e:
        print(f"âŒ ç›´æ¥APIæµ‹è¯•å¼‚å¸¸: {e}")
        return None

def test_proxy_api():
    """æµ‹è¯•æœ¬é¡¹ç›®ä»£ç†API"""
    print("\nğŸ”„ æµ‹è¯•æœ¬é¡¹ç›®ä»£ç†API...")

    headers = {
        'Content-Type': 'application/json'
    }

    data = {
        "model": "claude-3-5-haiku-20241022",
        "max_tokens": 500,
        "messages": [
            {"role": "user", "content": "è¯·ç®€è¦å›ç­”1+1ç­‰äºå¤šå°‘ï¼Ÿ"}
        ],
        "stream": True
    }

    try:
        response = requests.post(
            "http://127.0.0.1:8080/v1/messages",
            headers=headers,
            json=data,
            stream=True,
            timeout=30
        )

        if response.status_code == 200:
            analyzer = SSEAnalyzer()
            return analyzer.analyze_sse_stream(response, "Proxy API")
        else:
            print(f"âŒ ä»£ç†APIè¯·æ±‚å¤±è´¥: {response.status_code}")
            return None

    except Exception as e:
        print(f"âŒ ä»£ç†APIæµ‹è¯•å¼‚å¸¸: {e}")
        return None

def compare_and_analyze(direct_result, proxy_result):
    """å¯¹æ¯”åˆ†æç»“æœ"""
    print("\n" + "="*60)
    print("ğŸ“Š SSEæ•°æ®æµå¯¹æ¯”åˆ†æ")
    print("="*60)

    if not direct_result and not proxy_result:
        print("âŒ ä¸¤ä¸ªAPIéƒ½æ— æ³•è®¿é—®")
        return

    if direct_result:
        print(f"\nğŸ”µ ç›´æ¥Anthropic APIåˆ†æ:")
        print(f"   æ€»æ•°æ®å—æ•°: {direct_result['total_chunks']}")
        print(f"   æ€»ä¼ è¾“æ—¶é—´: {direct_result['total_time_ms']:.2f}ms")
        if 'avg_interval_ms' in direct_result:
            print(f"   å¹³å‡é—´éš”: {direct_result['avg_interval_ms']:.2f}ms")
            print(f"   æœ€å¤§é—´éš”: {direct_result['max_interval_ms']:.2f}ms")
            print(f"   æœ€å°é—´éš”: {direct_result['min_interval_ms']:.2f}ms")
            print(f"   é—´éš”æ ‡å‡†å·®: {direct_result['interval_std']:.2f}ms")
            print(f"   å¤§é—´éš”(>100ms): {len(direct_result['large_intervals'])}ä¸ª")
            print(f"   å°é—´éš”(<10ms): {len(direct_result['small_intervals'])}ä¸ª")
        print(f"   æ•°æ®å—ç±»å‹: {direct_result['block_types']}")

    if proxy_result:
        print(f"\nğŸŸ¡ æœ¬é¡¹ç›®ä»£ç†APIåˆ†æ:")
        print(f"   æ€»æ•°æ®å—æ•°: {proxy_result['total_chunks']}")
        print(f"   æ€»ä¼ è¾“æ—¶é—´: {proxy_result['total_time_ms']:.2f}ms")
        if 'avg_interval_ms' in proxy_result:
            print(f"   å¹³å‡é—´éš”: {proxy_result['avg_interval_ms']:.2f}ms")
            print(f"   æœ€å¤§é—´éš”: {proxy_result['max_interval_ms']:.2f}ms")
            print(f"   æœ€å°é—´éš”: {proxy_result['min_interval_ms']:.2f}ms")
            print(f"   é—´éš”æ ‡å‡†å·®: {proxy_result['interval_std']:.2f}ms")
            print(f"   å¤§é—´éš”(>100ms): {len(proxy_result['large_intervals'])}ä¸ª")
            print(f"   å°é—´éš”(<10ms): {len(proxy_result['small_intervals'])}ä¸ª")
        print(f"   æ•°æ®å—ç±»å‹: {proxy_result['block_types']}")

    # å¯¹æ¯”åˆ†æ
    if direct_result and proxy_result:
        print(f"\nğŸ” å…³é”®å·®å¼‚åˆ†æ:")

        # æ•°æ®å—æ•°é‡å¯¹æ¯”
        chunk_diff = proxy_result['total_chunks'] - direct_result['total_chunks']
        print(f"   æ•°æ®å—æ•°é‡å·®å¼‚: {chunk_diff:+d} ({'ä»£ç†æ›´å¤š' if chunk_diff > 0 else 'ä»£ç†æ›´å°‘'})")

        # æ—¶é—´å¯¹æ¯”
        if 'avg_interval_ms' in direct_result and 'avg_interval_ms' in proxy_result:
            interval_diff = proxy_result['avg_interval_ms'] - direct_result['avg_interval_ms']
            print(f"   å¹³å‡é—´éš”å·®å¼‚: {interval_diff:+.2f}ms ({'ä»£ç†æ›´æ…¢' if interval_diff > 0 else 'ä»£ç†æ›´å¿«'})")

            std_diff = proxy_result['interval_std'] - direct_result['interval_std']
            print(f"   é—´éš”ç¨³å®šæ€§å·®å¼‚: {std_diff:+.2f}ms ({'ä»£ç†æ›´ä¸ç¨³å®š' if std_diff > 0 else 'ä»£ç†æ›´ç¨³å®š'})")

        # æ•°æ®å—ç±»å‹å¯¹æ¯”
        direct_types = set(direct_result['block_types'].keys())
        proxy_types = set(proxy_result['block_types'].keys())
        type_diff = proxy_types - direct_types
        if type_diff:
            print(f"   ä»£ç†ç‰¹æœ‰æ•°æ®å—ç±»å‹: {type_diff}")

        # é—ªçƒé—®é¢˜å¯èƒ½çš„åŸå› 
        print(f"\nğŸš¨ é—ªçƒé—®é¢˜å¯èƒ½åŸå› :")
        if 'large_intervals' in proxy_result and len(proxy_result['large_intervals']) > 2:
            print(f"   âš ï¸ ä»£ç†APIå­˜åœ¨è¿‡å¤šå¤§é—´éš”ä¼ è¾“ ({len(proxy_result['large_intervals'])}ä¸ª >100ms)")
        if 'interval_std' in proxy_result and proxy_result['interval_std'] > 50:
            print(f"   âš ï¸ ä»£ç†APIä¼ è¾“é—´éš”ä¸ç¨³å®š (æ ‡å‡†å·®: {proxy_result['interval_std']:.2f}ms)")
        if chunk_diff > 5:
            print(f"   âš ï¸ ä»£ç†APIç”Ÿæˆäº†è¿‡å¤šæ•°æ®å— (å¤š{chunk_diff}ä¸ª)")
        if proxy_result['total_time_ms'] > direct_result.get('total_time_ms', 0) * 1.5:
            print(f"   âš ï¸ ä»£ç†APIä¼ è¾“æ—¶é—´è¿‡é•¿")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”¬ SSEæ•°æ®æµæ·±åº¦åˆ†æ - å®šä½Claude Codeé—ªçƒçœŸæ­£åŸå› ")
    print("="*60)

    # æµ‹è¯•ä»£ç†API
    proxy_result = test_proxy_api()

    # ç›´æ¥Anthropic APIæµ‹è¯•éœ€è¦çœŸå®å¯†é’¥ï¼Œè¿™é‡Œåªåšç¤ºä¾‹
    # å¦‚æœä½ æœ‰å¯†é’¥ï¼Œå¯ä»¥å–æ¶ˆæ³¨é‡Šä¸‹é¢çš„ä»£ç 
    # direct_result = test_direct_anthropic_api()
    direct_result = None

    # å¯¹æ¯”åˆ†æ
    compare_and_analyze(direct_result, proxy_result)

    # å¦‚æœåªæœ‰ä»£ç†APIæ•°æ®ï¼Œä¹Ÿè¿›è¡Œæ·±å…¥åˆ†æ
    if proxy_result and not direct_result:
        print(f"\nğŸ”¬ ä»£ç†APIæ·±å…¥åˆ†æ:")
        if 'large_intervals' in proxy_result and proxy_result['large_intervals']:
            print(f"   å‘ç° {len(proxy_result['large_intervals'])} ä¸ªå¤§é—´éš” (>100ms):")
            for i, interval in enumerate(proxy_result['large_intervals'][:5]):
                print(f"     ç¬¬{i+1}ä¸ªå¤§é—´éš”: {interval:.2f}ms")

        if 'interval_std' in proxy_result and proxy_result['interval_std'] > 30:
            print(f"   âš ï¸ ä¼ è¾“é—´éš”ä¸ç¨³å®šï¼Œæ ‡å‡†å·®: {proxy_result['interval_std']:.2f}ms")
            print("   è¿™å¯èƒ½æ˜¯å¯¼è‡´Claude Codeç•Œé¢é—ªçƒçš„ä¸»è¦åŸå› ")

        print(f"\nğŸ’¡ å»ºè®®ä¿®å¤æ–¹å‘:")
        print("   1. è¿›ä¸€æ­¥ä¼˜åŒ–æ•°æ®æµçš„æ—¶é—´é—´éš”æ§åˆ¶")
        print("   2. å®ç°æ›´ç²¾ç¡®çš„å®šæ—¶åˆ·æ–°æœºåˆ¶")
        print("   3. æ·»åŠ æ•°æ®æµç¼“å†²ï¼Œç¡®ä¿å¹³æ»‘è¾“å‡º")
        print("   4. è€ƒè™‘æ¨¡æ‹Ÿç›´æ¥APIçš„ä¼ è¾“æ¨¡å¼")

if __name__ == "__main__":
    main()