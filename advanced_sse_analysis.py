#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é«˜çº§SSEåˆ†æ - å®šä½çœŸæ­£é—ªçƒæ ¹å› 
"""

import time
import json
import requests
import threading
from collections import defaultdict

def capture_detailed_sse_stream():
    """æ•è·è¯¦ç»†çš„SSEæµæ•°æ®"""
    headers = {'Content-Type': 'application/json'}

    # ä½¿ç”¨ä¸€ä¸ªç®€å•çš„æµ‹è¯•è¯·æ±‚
    data = {
        "model": "claude-3-haiku-20240307",  # ä½¿ç”¨é…ç½®ä¸­çš„æ¨¡å‹
        "max_tokens": 200,
        "messages": [{"role": "user", "content": "Hi"}],
        "stream": True
    }

    print("è¯¦ç»†æ•è·SSEæ•°æ®æµ...")
    print("-" * 60)

    events = []
    start_time = time.time()

    try:
        response = requests.post(
            "http://127.0.0.1:8080/v1/messages",
            headers=headers,
            json=data,
            stream=True,
            timeout=20
        )

        if response.status_code != 200:
            print(f"APIè¯·æ±‚å¤±è´¥: {response.status_code}")
            return events

        for i, line in enumerate(response.iter_lines(decode_unicode=True)):
            current_time = time.time()
            elapsed = (current_time - start_time) * 1000

            if line:
                # è¯¦ç»†è®°å½•æ¯ä¸€æ¡æ•°æ®
                event = {
                    'index': i + 1,
                    'timestamp': current_time,
                    'elapsed_ms': elapsed,
                    'raw_line': line,
                    'is_data': line.startswith('data:'),
                    'content': line[5:].strip() if line.startswith('data:') else line,
                    'size_bytes': len(line.encode('utf-8'))
                }
                events.append(event)

                # é€æ¡æ‰“å°è¯¦ç»†ä¿¡æ¯
                print(f"{event['index']:3d} | {event['elapsed_ms']:6.2f}ms | {event['size_bytes']:3d}B | {line}")

                if '[DONE]' in line:
                    break

    except Exception as e:
        print(f"æ•è·å¼‚å¸¸: {e}")

    return events

def analyze_timing_patterns(events):
    """åˆ†ææ—¶é—´æ¨¡å¼"""
    if len(events) < 2:
        print("æ•°æ®ä¸è¶³ï¼Œæ— æ³•åˆ†ææ—¶é—´æ¨¡å¼")
        return

    print("\n" + "=" * 60)
    print("æ—¶é—´æ¨¡å¼åˆ†æ")
    print("=" * 60)

    # è®¡ç®—ç›¸é‚»äº‹ä»¶çš„é—´éš”
    intervals = []
    for i in range(1, len(events)):
        interval = events[i]['elapsed_ms'] - events[i-1]['elapsed_ms']
        intervals.append(interval)

    if intervals:
        # åŸºæœ¬ç»Ÿè®¡
        avg_interval = sum(intervals) / len(intervals)
        max_interval = max(intervals)
        min_interval = min(intervals)

        print(f"æ€»äº‹ä»¶æ•°: {len(events)}")
        print(f"é—´éš”ç»Ÿè®¡:")
        print(f"  å¹³å‡: {avg_interval:.2f}ms")
        print(f"  æœ€å¤§: {max_interval:.2f}ms")
        print(f"  æœ€å°: {min_interval:.2f}ms")
        print(f"  æ ‡å‡†å·®: {calculate_std(intervals):.2f}ms")

        # åˆ†æ®µåˆ†æ
        print(f"\né—´éš”åˆ†æ®µåˆ†æ:")
        segments = [
            (0, 5, "ç¬æ—¶"),
            (5, 20, "å¿«é€Ÿ"),
            (20, 50, "æ­£å¸¸"),
            (50, 100, "è¾ƒæ…¢"),
            (100, float('inf'), "å¼‚å¸¸æ…¢")
        ]

        for min_val, max_val, label in segments:
            count = sum(1 for x in intervals if min_val <= x < max_val)
            percentage = count / len(intervals) * 100
            print(f"  {label}[{min_val}-{max_val if max_val != float('inf') else 'âˆ'}ms): {count}ä¸ª ({percentage:.1f}%)")

        # è¯†åˆ«é—®é¢˜æ¨¡å¼
        print(f"\né—®é¢˜æ£€æµ‹:")

        # è¿ç»­å°å—æ£€æµ‹ï¼ˆæ•°æ®è½°ç‚¸ï¼‰
        consecutive_small = find_consecutive_small(intervals, threshold=10, min_consecutive=3)
        if consecutive_small:
            print(f"  ğŸš¨ è¿ç»­å°å—(æ•°æ®è½°ç‚¸æ¨¡å¼): æ‰¾åˆ°{len(consecutive_small)}ç»„")
            for start_pos, length in consecutive_small[:3]:
                print(f"    ä½ç½®{start_pos}-{start_pos+length-1}: {length}ä¸ªè¿ç»­å°å—")

        # å¤§é—´éš”æ£€æµ‹ï¼ˆå¡é¡¿æ¨¡å¼ï¼‰
        large_intervals = [(i, interval) for i, interval in enumerate(intervals) if interval > 100]
        if large_intervals:
            print(f"  ğŸš¨ å¤§é—´éš”(å¡é¡¿æ¨¡å¼): {len(large_intervals)}ä¸ª")
            for pos, interval in large_intervals[:5]:
                print(f"    ä½ç½®{pos}: {interval:.2f}ms")

        # é—´éš”çªå˜æ£€æµ‹ï¼ˆä¸ç¨³å®šä¼ è¾“ï¼‰
        jumps = detect_interval_jumps(intervals, threshold=5.0)
        if jumps:
            print(f"  ğŸš¨ é—´éš”çªå˜(ä¸ç¨³å®šä¼ è¾“): {len(jumps)}æ¬¡")

    return intervals

def analyze_content_patterns(events):
    """åˆ†æå†…å®¹æ¨¡å¼"""
    print(f"\n" + "=" * 60)
    print("å†…å®¹æ¨¡å¼åˆ†æ")
    print("=" * 60)

    content_types = defaultdict(int)
    message_start_events = []
    content_block_events = []
    delta_events = []

    for event in events:
        if event['is_data']:
            content = event['content']
            if content == '[DONE]':
                content_types['DONE'] += 1
            else:
                try:
                    data = json.loads(content)
                    msg_type = data.get('type', 'unknown')
                    content_types[msg_type] += 1

                    if msg_type == 'message_start':
                        message_start_events.append(event)
                    elif 'content_block' in msg_type:
                        content_block_events.append(event)
                    elif 'delta' in msg_type:
                        delta_events.append(event)

                except json.JSONDecodeError:
                    content_types['invalid_json'] += 1

    print(f"æ•°æ®å—ç±»å‹ç»Ÿè®¡:")
    for content_type, count in sorted(content_types.items()):
        print(f"  {content_type}: {count}")

    # åˆ†ææ—¶é—´åˆ†å¸ƒ
    if delta_events:
        print(f"\nå†…å®¹å¢é‡åˆ†æ:")
        delta_intervals = []
        for i in range(1, len(delta_events)):
            interval = delta_events[i]['elapsed_ms'] - delta_events[i-1]['elapsed_ms']
            delta_intervals.append(interval)

        if delta_intervals:
            print(f"  å¹³å‡å¢é‡é—´éš”: {sum(delta_intervals)/len(delta_intervals):.2f}ms")
            print(f"  å¢é‡é—´éš”æ ‡å‡†å·®: {calculate_std(delta_intervals):.2f}ms")

def calculate_std(values):
    """è®¡ç®—æ ‡å‡†å·®"""
    if not values:
        return 0
    mean = sum(values) / len(values)
    variance = sum((x - mean) ** 2 for x in values) / len(values)
    return variance ** 0.5

def find_consecutive_small(intervals, threshold=10, min_consecutive=3):
    """æŸ¥æ‰¾è¿ç»­çš„å°é—´éš”"""
    consecutive = []
    current_start = None
    current_length = 0

    for i, interval in enumerate(intervals):
        if interval < threshold:
            if current_start is None:
                current_start = i
            current_length += 1
        else:
            if current_length >= min_consecutive:
                consecutive.append((current_start, current_length))
            current_start = None
            current_length = 0

    # æ£€æŸ¥æœ€åä¸€ç»„
    if current_length >= min_consecutive:
        consecutive.append((current_start, current_length))

    return consecutive

def detect_interval_jumps(intervals, threshold=5.0):
    """æ£€æµ‹é—´éš”çªå˜"""
    jumps = []
    for i in range(1, len(intervals)):
        if intervals[i-1] > 0:
            ratio = intervals[i] / intervals[i-1]
            if ratio > threshold or ratio < 1/threshold:
                jumps.append((i-1, intervals[i-1], intervals[i], ratio))
    return jumps

def diagnose_flicker_cause(events, intervals):
    """è¯Šæ–­é—ªçƒåŸå› """
    print(f"\n" + "=" * 60)
    print("é—ªçƒé—®é¢˜è¯Šæ–­")
    print("=" * 60)

    issues = []

    # æ£€æŸ¥æ•°æ®è½°ç‚¸æ¨¡å¼
    consecutive_small = find_consecutive_small(intervals, threshold=5, min_consecutive=5)
    if consecutive_small:
        issues.append("æ•°æ®è½°ç‚¸æ¨¡å¼: è¿ç»­å¤šä¸ªå°é—´éš”(5msä»¥ä¸‹)çš„å¿«é€Ÿæ•°æ®ä¼ è¾“")

    # æ£€æŸ¥å¡é¡¿æ¨¡å¼
    large_intervals = [i for i in intervals if i > 150]
    if len(large_intervals) > 2:
        issues.append("å¡é¡¿æ¨¡å¼: å¤šä¸ªè¶…è¿‡150msçš„å¤§é—´éš”")

    # æ£€æŸ¥ä¸ç¨³å®šä¼ è¾“
    if intervals and calculate_std(intervals) > 50:
        issues.append("ä¸ç¨³å®šä¼ è¾“: é—´éš”æ ‡å‡†å·®è¿‡å¤§ï¼Œä¼ è¾“èŠ‚å¥ä¸å‡åŒ€")

    # æ£€æŸ¥æ•°æ®å—æ•°é‡
    if len(events) > 50:
        issues.append("æ•°æ®å—è¿‡å¤š: ç”Ÿæˆçš„æ•°æ®å—æ•°é‡è¿‡å¤šï¼Œå¯èƒ½å¯¼è‡´å¤„ç†è´Ÿæ‹…")

    # æ£€æŸ¥æ€»ä¼ è¾“æ—¶é—´
    if events and events[-1]['elapsed_ms'] > 5000:
        issues.append("ä¼ è¾“æ—¶é—´è¿‡é•¿: æ€»ä¼ è¾“æ—¶é—´è¶…è¿‡5ç§’")

    if issues:
        print("ğŸš¨ å‘ç°çš„é—®é¢˜:")
        for i, issue in enumerate(issues, 1):
            print(f"  {i}. {issue}")
    else:
        print("âœ… æœªå‘ç°æ˜æ˜¾çš„é—ªçƒé—®é¢˜")

    # ç»™å‡ºä¿®å¤å»ºè®®
    print(f"\nğŸ’¡ ä¿®å¤å»ºè®®:")
    if consecutive_small:
        print("  - å®ç°æ›´ä¸¥æ ¼çš„ç¼“å†²æ§åˆ¶ï¼Œé¿å…æ•°æ®è½°ç‚¸")
        print("  - å¢åŠ æœ€å°é—´éš”é™åˆ¶ï¼Œç¡®ä¿å¹³æ»‘è¾“å‡º")
    if large_intervals:
        print("  - ä¼˜åŒ–ä¸Šæ¸¸APIè°ƒç”¨ï¼Œå‡å°‘å¤§é—´éš”")
        print("  - å®ç°å¿ƒè·³æœºåˆ¶ï¼Œä¿æŒè¿æ¥æ´»è·ƒ")
    if intervals and calculate_std(intervals) > 50:
        print("  - å®ç°å®šæ—¶å™¨æ§åˆ¶ï¼Œç¡®ä¿å‡åŒ€ä¼ è¾“")
        print("  - æ·»åŠ è‡ªé€‚åº”ç¼“å†²ï¼Œæ ¹æ®ä¼ è¾“é€Ÿåº¦è°ƒæ•´")

def main():
    """ä¸»å‡½æ•°"""
    print("é«˜çº§SSEåˆ†æ - å®šä½é—ªçƒçœŸæ­£æ ¹å› ")
    print("=" * 60)

    # æ•è·è¯¦ç»†æ•°æ®
    events = capture_detailed_sse_stream()

    if not events:
        print("æ— æ³•è·å–SSEæ•°æ®ï¼Œè¯·æ£€æŸ¥æœåŠ¡çŠ¶æ€")
        return

    # åˆ†ææ—¶é—´æ¨¡å¼
    intervals = analyze_timing_patterns(events)

    # åˆ†æå†…å®¹æ¨¡å¼
    analyze_content_patterns(events)

    # è¯Šæ–­é—ªçƒåŸå› 
    diagnose_flicker_cause(events, intervals)

if __name__ == "__main__":
    main()