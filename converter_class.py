import json
import logging
from typing import Dict, List, Optional, Any
import requests
from config_manager import ConfigManager

# è®¾ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

class AnthropicToOpenAIConverter:
    def __init__(self, config_manager: ConfigManager = None):
        self.config_manager = config_manager or ConfigManager()
        
    def convert_messages(self, anthropic_messages: List[Dict]) -> List[Dict]:
        """å°†Anthropicæ¶ˆæ¯æ ¼å¼è½¬æ¢ä¸ºOpenAIæ¶ˆæ¯æ ¼å¼"""
        openai_messages = []
        
        for message in anthropic_messages:
            role = message.get('role', '')
            content = message.get('content', '')
            
            # è§’è‰²æ˜ å°„
            if role == 'user':
                openai_role = 'user'
            elif role == 'assistant':
                openai_role = 'assistant'
            else:
                openai_role = 'user'  # é»˜è®¤æ˜ å°„
            
            # å¤„ç†å†…å®¹æ ¼å¼ï¼ˆAnthropicå¯èƒ½æ˜¯å¯¹è±¡æ•°ç»„ï¼ŒOpenAIæ˜¯å­—ç¬¦ä¸²æˆ–å¯¹è±¡æ•°ç»„ï¼‰
            if isinstance(content, list):
                # å¦‚æœæ˜¯å†…å®¹æ•°ç»„ï¼Œæå–æ–‡æœ¬
                text_content = ''
                for content_item in content:
                    if content_item.get('type') == 'text':
                        text_content += content_item.get('text', '')
                openai_messages.append({
                    'role': openai_role,
                    'content': text_content
                })
            else:
                # å¦‚æœæ˜¯çº¯æ–‡æœ¬
                openai_messages.append({
                    'role': openai_role,
                    'content': content
                })
        
        return openai_messages
    
    def convert_request(self, anthropic_request: Dict) -> Dict:
        """å°†Anthropic APIè¯·æ±‚è½¬æ¢ä¸ºOpenAI APIè¯·æ±‚"""
        model = anthropic_request.get('model', 'gpt-4')
        
        openai_request = {
            'model': self._convert_model(model),
            'max_tokens': anthropic_request.get('max_tokens', 1024),
            'messages': [],
            'temperature': anthropic_request.get('temperature', 0.7),
        }
        
        # å¤„ç†ç³»ç»Ÿæ¶ˆæ¯
        if 'system' in anthropic_request:
            openai_request['messages'].insert(0, {
                'role': 'system',
                'content': anthropic_request['system']
            })
        
        # è½¬æ¢æ¶ˆæ¯
        anthropic_messages = anthropic_request.get('messages', [])
        openai_request['messages'].extend(self.convert_messages(anthropic_messages))
        
        # å¤„ç†å·¥å…·è°ƒç”¨ï¼ˆClaude Codeå…³é”®åŠŸèƒ½ï¼‰
        if 'tools' in anthropic_request:
            # è½¬æ¢Anthropicå·¥å…·æ ¼å¼ä¸ºOpenAIæ ¼å¼
            openai_tools = []
            for tool in anthropic_request['tools']:
                openai_tool = {
                    "type": "function",
                    "function": {
                        "name": tool.get('name', ''),
                        "description": tool.get('description', ''),
                        "parameters": tool.get('input_schema', {})
                    }
                }
                openai_tools.append(openai_tool)
            
            openai_request['tools'] = openai_tools
            logger.info(f"è½¬æ¢å·¥å…·å®šä¹‰: {len(openai_tools)} ä¸ªå·¥å…·")
        
        if 'tool_choice' in anthropic_request:
            openai_request['tool_choice'] = anthropic_request['tool_choice']
        
        # å¯é€‰å‚æ•°è½¬æ¢
        if 'top_p' in anthropic_request:
            openai_request['top_p'] = anthropic_request['top_p']
        
        if 'stop_sequences' in anthropic_request:
            openai_request['stop'] = anthropic_request['stop_sequences']
        
        return openai_request
    
    def _convert_model(self, anthropic_model: str) -> str:
        """ç›´æ¥ä½¿ç”¨ä¼ å…¥çš„æ¨¡å‹åç§°ï¼Œä¸è¿›è¡Œæ˜ å°„"""
        return anthropic_model
    
    def convert_response(self, openai_response: Dict) -> Dict:
        """å°†OpenAI APIå“åº”è½¬æ¢ä¸ºAnthropicæ ¼å¼"""
        
        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ£€æŸ¥OpenAI APIé”™è¯¯å“åº”
        if self._is_error_response(openai_response):
            error_msg = openai_response.get('msg', 'Unknown API error')
            error_status = openai_response.get('status', '500')
            logger.error(f"OpenAI APIè¿”å›é”™è¯¯: {error_status} - {error_msg}")
            raise Exception(f"OpenAI API error: {error_status} - {error_msg}")
        
        anthropic_response = {
            'id': openai_response.get('id', ''),
            'type': 'message',
            'role': 'assistant',
            'content': [],
            'model': self._reverse_convert_model(openai_response.get('model', '')),
            'stop_reason': 'end_turn',
            'usage': self._convert_usage(openai_response.get('usage', {}))
        }
        
        # è½¬æ¢å†…å®¹
        if openai_response.get('choices'):
            choice = openai_response['choices'][0]
            message = choice.get('message', {})
            
            # å¤„ç†å·¥å…·è°ƒç”¨å“åº”ï¼ˆClaude Codeå…³é”®åŠŸèƒ½ï¼‰
            if 'tool_calls' in message:
                tool_calls = message['tool_calls']
                logger.info(f"è½¬æ¢å·¥å…·è°ƒç”¨å“åº”: {len(tool_calls)} ä¸ªå·¥å…·è°ƒç”¨")
                
                # å°†å·¥å…·è°ƒç”¨è½¬æ¢ä¸ºClaudeæ ¼å¼
                for tool_call in tool_calls:
                    function = tool_call.get('function', {})
                    anthropic_response['content'].append({
                        'type': 'tool_use',
                        'id': tool_call.get('id', ''),
                        'name': function.get('name', ''),
                        'input': json.loads(function.get('arguments', '{}'))
                    })
                
                anthropic_response['stop_reason'] = 'tool_use'
            else:
                # å¤„ç†æ™®é€šæ–‡æœ¬å“åº”
                message_content = message.get('content', '')
                
                # ğŸ”´ å…³é”®ä¿®å¤ï¼šglm-4.6æ¨¡å‹ä½¿ç”¨reasoning_contentå­—æ®µè€Œä¸æ˜¯contentå­—æ®µ
                if not message_content:
                    message_content = message.get('reasoning_content', '')
                
                if message_content:
                    anthropic_response['content'] = [{
                        'type': 'text',
                        'text': message_content
                    }]
            
            anthropic_response['stop_reason'] = self._convert_stop_reason(
                choice.get('finish_reason', 'stop')
            )
        
        return anthropic_response
    
    def _reverse_convert_model(self, openai_model: str) -> str:
        """ç›´æ¥ä½¿ç”¨è¿”å›çš„æ¨¡å‹åç§°ï¼Œä¸è¿›è¡Œæ˜ å°„"""
        return openai_model
    
    def _convert_stop_reason(self, openai_stop_reason: str) -> str:
        """è½¬æ¢åœæ­¢åŸå› """
        reason_mapping = {
            'stop': 'end_turn',
            'length': 'max_tokens',
            'content_filter': 'stop_sequence',
            'tool_calls': 'tool_use'  # ğŸ”´ å…³é”®ä¿®å¤ï¼šå·¥å…·è°ƒç”¨åº”è¯¥æ˜ å°„ä¸º tool_use
        }
        return reason_mapping.get(openai_stop_reason, 'end_turn')
    
    def _convert_usage(self, openai_usage: Dict) -> Dict:
        """è½¬æ¢ä½¿ç”¨é‡ç»Ÿè®¡"""
        return {
            'input_tokens': openai_usage.get('prompt_tokens', 0),
            'output_tokens': openai_usage.get('completion_tokens', 0)
        }
    
    def _is_error_response(self, openai_response: Dict) -> bool:
        """æ£€æµ‹OpenAI APIé”™è¯¯å“åº”"""
        # æ£€æŸ¥æ˜æ˜¾çš„é”™è¯¯å­—æ®µ
        if 'status' in openai_response and openai_response['status'] != '200':
            return True
        
        if 'error' in openai_response:
            return True
        
        # æ£€æŸ¥æ˜¯å¦ç¼ºå°‘å¿…è¦å­—æ®µ
        if 'choices' not in openai_response:
            return True
        
        # æ£€æŸ¥bodyå­—æ®µä¸ºç©ºï¼ˆæŸäº›APIé”™è¯¯æ ¼å¼ï¼‰
        if openai_response.get('body') is None and 'choices' not in openai_response:
            return True
        
        return False
